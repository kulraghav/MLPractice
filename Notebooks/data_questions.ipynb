{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "81: chi-square test\n",
    "80: group by + join (using with)\n",
    "79: INCOMPLETE (do not understand the problem)\n",
    "78: max and second max\n",
    "77: group by + join\n",
    "76: resampling imbalanced data (oversampling, undersampling, one-class learning, asym-loss function)\n",
    "75: group by + avg\n",
    "74: df['farenheit'] = df['celcius'].apply(lambda F: 5*(F-32)/9)\n",
    "73: single sample t-test\n",
    "72: two update queries\n",
    "71: df.apply + datetime\n",
    "70: inside loop increments counter before printing\n",
    "69: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Problem 81\n",
    "    fitness: low, medium, medium-high, high\n",
    "    https://machinelearningmastery.com/chi-squared-test-for-machine-learning/\n",
    "\"\"\"\n",
    "never_smoked = [113, 113, 110, 159]\n",
    "former_smokers = [119, 135, 172, 190]\n",
    "one_to_nine_daily = [77, 91, 86, 65]\n",
    "at_least_ten_daily = [181, 152, 124, 73]\n",
    "\n",
    "\"\"\"\n",
    "    Is there a relation between smoking and fitness level ?\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'never_smoked': never_smoked, \n",
    "                  'former_smokers': former_smokers, \n",
    "                  'one_to_nine_daily': one_to_nine_daily,\n",
    "                  'at_least_ten_daily': at_least_ten_daily}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['low', 'medium', 'med-high', 'high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>med-high</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>never_smoked</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>110</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>former_smokers</th>\n",
       "      <td>119</td>\n",
       "      <td>135</td>\n",
       "      <td>172</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one_to_nine_daily</th>\n",
       "      <td>77</td>\n",
       "      <td>91</td>\n",
       "      <td>86</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at_least_ten_daily</th>\n",
       "      <td>181</td>\n",
       "      <td>152</td>\n",
       "      <td>124</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    low  medium  med-high  high\n",
       "never_smoked        113     113       110   159\n",
       "former_smokers      119     135       172   190\n",
       "one_to_nine_daily    77      91        86    65\n",
       "at_least_ten_daily  181     152       124    73"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H0: the distribution of fitness level is independent of smoker status\n",
      "\n",
      "\n",
      "                    low  medium  med-high  high\n",
      "never_smoked        113     113       110   159\n",
      "former_smokers      119     135       172   190\n",
      "one_to_nine_daily    77      91        86    65\n",
      "at_least_ten_daily  181     152       124    73\n",
      "\n",
      "\n",
      "Degrees of freedom = 9\n",
      "The expected values are:\n",
      "[[123.75       124.00255102 124.25510204 122.99234694]\n",
      " [154.         154.31428571 154.62857143 153.05714286]\n",
      " [ 79.75        79.9127551   80.0755102   79.26173469]\n",
      " [132.5        132.77040816 133.04081633 131.68877551]]\n",
      "\n",
      "\n",
      "Interpreting the test statistics:\n",
      "probability=0.950, critical=16.919, stat=87.273\n",
      "Dependent (reject H0)\n",
      "\n",
      "\n",
      "p-value\n",
      "significance=0.050, p=0.000\n",
      "Dependent (reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "print(\"H0: the distribution of fitness level is independent of smoker status\")\n",
    "print(\"\\n\")\n",
    "# contingency table\n",
    "table = df\n",
    "print(table)\n",
    "print('\\n')\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('Degrees of freedom = {}'.format(dof))\n",
    "print(\"The expected values are:\")\n",
    "print(expected)\n",
    "print(\"\\n\")\n",
    "print(\"Interpreting the test statistics:\")\n",
    "# interpret test-statistic\n",
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "if abs(stat) >= critical:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')\n",
    "print('\\n')    \n",
    "print(\"p-value\")    \n",
    "# interpret p-value\n",
    "alpha = 1.0 - prob\n",
    "print('significance=%.3f, p=%.3f' % (alpha, p))\n",
    "if p <= alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_never_smoked = (113 + 113 + 110 + 159) \n",
    "num_low_fitness = (113 + 119 + 77 + 181) \n",
    "total = (113 + 113 + 110 + 159 + 119 + 135 + 172 + 190 + 77 + 91 + 86 + 65 + 181 + 152 + 124 + 73)\n",
    "\n",
    "expected_never_smoke_and_low_fitness = num_never_smoked*num_low_fitness/total\n",
    "expected_never_smoke_and_low_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    airbnb: channel attribution\n",
    "    \n",
    "    interesting link: https://medium.com/data-from-the-trenches/marketing-attribution-e7fa7ae9e919\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../Data/channel_attribution/airbnb_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_account_created</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>35.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>Moweb</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Mobile Safari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtl0dijy2j</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>Moweb</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Mobile Safari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xx0ulgorjt</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6c6puo6ix0</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>IE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>czqhjk3yfe</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Safari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id date_account_created     gender   age signup_method language  \\\n",
       "0  5uwns89zht           2014-07-01     FEMALE  35.0      facebook       en   \n",
       "1  jtl0dijy2j           2014-07-01  -unknown-   NaN         basic       en   \n",
       "2  xx0ulgorjt           2014-07-01  -unknown-   NaN         basic       en   \n",
       "3  6c6puo6ix0           2014-07-01  -unknown-   NaN         basic       en   \n",
       "4  czqhjk3yfe           2014-07-01  -unknown-   NaN         basic       en   \n",
       "\n",
       "  affiliate_channel affiliate_provider signup_app first_device_type  \\\n",
       "0            direct             direct      Moweb            iPhone   \n",
       "1            direct             direct      Moweb            iPhone   \n",
       "2            direct             direct        Web   Windows Desktop   \n",
       "3            direct             direct        Web   Windows Desktop   \n",
       "4            direct             direct        Web       Mac Desktop   \n",
       "\n",
       "   first_browser  \n",
       "0  Mobile Safari  \n",
       "1  Mobile Safari  \n",
       "2         Chrome  \n",
       "3             IE  \n",
       "4         Safari  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       object\n",
       "date_account_created     object\n",
       "gender                   object\n",
       "age                     float64\n",
       "signup_method            object\n",
       "language                 object\n",
       "affiliate_channel        object\n",
       "affiliate_provider       object\n",
       "signup_app               object\n",
       "first_device_type        object\n",
       "first_browser            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['date_account_created'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "direct           43844\n",
       "sem-brand        10394\n",
       "seo               5699\n",
       "sem-non-brand     1231\n",
       "other              586\n",
       "remarketing        172\n",
       "content            170\n",
       "Name: affiliate_channel, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['affiliate_channel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['direct', 'google', 'bing', 'facebook', 'other', 'craigslist',\n",
       "       'padmapper', 'email-marketing', 'yahoo', 'baidu', 'naver', 'gsp',\n",
       "       'facebook-open-graph', 'meetup', 'vast', 'daum', 'yandex'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['affiliate_provider'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Moweb', 'Web', 'iOS', 'Android'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['signup_app'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mobile Safari', 'Chrome', 'IE', 'Safari', '-unknown-', 'Firefox',\n",
       "       'Chrome Mobile', 'Android Browser', 'IE Mobile',\n",
       "       'BlackBerry Browser', 'Opera', 'Silk', 'Mobile Firefox',\n",
       "       'AOL Explorer', 'SeaMonkey', 'Opera Mobile', 'wOSBrowser',\n",
       "       'Chromium', 'Apple Mail', 'Maxthon', 'IBrowse', 'Sogou Explorer',\n",
       "       'Iron', 'Yandex.Browser', 'SiteKiosk', 'Pale Moon',\n",
       "       'Nintendo Browser', 'Opera Mini', 'CometBird', 'IceWeasel',\n",
       "       'UC Browser'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['first_browser'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0.0\n",
      "date_account_created: 0.0\n",
      "gender: 0.0\n",
      "age: 0.4650219015717598\n",
      "signup_method: 0.0\n",
      "language: 0.0\n",
      "affiliate_channel: 0.0\n",
      "affiliate_provider: 0.0\n",
      "signup_app: 0.0\n",
      "first_device_type: 0.0\n",
      "first_browser: 0.0\n"
     ]
    }
   ],
   "source": [
    "def fraction_of_nans(df):\n",
    "    for column in df.columns.tolist():\n",
    "        print(\"{}: {}\".format(column, 1-df[column].count()/len(df)))\n",
    "        \n",
    "fraction_of_nans(df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['age'] = df['age'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    test if all ids are unique\n",
    "\"\"\"\n",
    "df['id'].nunique() == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling\n",
    "Can you explain what resampling is? Can you name 2 seperate resampling methods and explain the pros and cons?\n",
    "\n",
    "Resampling is remedy used when data is imbalanced.\n",
    "Let us say in binary classification problem (e.g. fraud detection), the number of positive samples (cases of fraud) available are much smaller compared to the number of negative samples.\n",
    "Why is it a problem ? Because many ML algorithms are unable to learn well from imbalanced datasets.\n",
    "https://stats.stackexchange.com/questions/247871/what-is-the-root-cause-of-the-class-imbalance-problem\n",
    "The stack-overflow answers seem to suggest that \"loss-functions that penalize both classes uniformly\" seem to be the root cause.\n",
    "\n",
    "How to solve the class-imbalance problem ?\n",
    "Apart from using balanced loss function, resampling methods seem to be used in practice.\n",
    "https://stats.stackexchange.com/questions/131255/class-imbalance-in-supervised-machine-learning/131259#131259\n",
    "\n",
    "There are 4 types: \n",
    "1. Oversampling smaller class\n",
    "2. Undersampling larger class\n",
    "3. One class learning (denoise the data)\n",
    "4. Asymmetric cost function\n",
    "\n",
    "Example of one-class svm: https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-sample t-test\n",
    "https://plot.ly/python/t-test/\n",
    "\n",
    "\n",
    "https://python-forum.io/Thread-Plot-a-stacked-bar-graph-using-plotly-offline-mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    selenimum toxicity of water\n",
    "    t-test\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "toxs = [0.051,\n",
    "0.0505,\n",
    "0.049,\n",
    "0.0516,\n",
    "0.052,\n",
    "0.0508,\n",
    "0.0506]\n",
    "\n",
    "danger = 0.05 # mg/L\n",
    "df = pd.DataFrame({'day': list(range(1, 8)), 'toxicity': toxs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  toxicity\n",
       "0    1    0.0510\n",
       "1    2    0.0505\n",
       "2    3    0.0490\n",
       "3    4    0.0516\n",
       "4    5    0.0520\n",
       "5    6    0.0508\n",
       "6    7    0.0506"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=2.173499949434694, pvalue=0.07271011867964246)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "from plotly.tools import FigureFactory as FF\n",
    "import plotly.plotly as py\n",
    "\n",
    "true_mu = 0.05\n",
    "\n",
    "onesample_results = ttest_1samp(df['toxicity'], true_mu)\n",
    "onesample_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghav/anaconda3/lib/python3.6/site-packages/plotly/tools.py:1545: UserWarning:\n",
      "\n",
      "plotly.tools.FigureFactory.create_table is deprecated. Use plotly.figure_factory.create_table\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///home/raghav/Practice/MLPractice/Notebooks/temp-plot.html'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, plot\n",
    "init_notebook_mode(connected=True)\n",
    " \n",
    "matrix_onesample = [\n",
    "    ['', 'Test Statistic', 'p-value'],\n",
    "    ['Sample Data', onesample_results[0], onesample_results[1]]\n",
    "]\n",
    "\n",
    "onesample_table = FF.create_table(matrix_onesample, index=True)\n",
    "plot(onesample_table, filename='onesample-table')\n",
    "# py.iplot(onesample_table, filename='onesample-table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two sample t-test\n",
    "https://towardsdatascience.com/inferential-statistics-series-t-test-using-numpy-2718f8f9bf2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 5.963825577165308\n",
      "p = 1.2137653838006912e-05\n",
      "t = 5.963825577165308\n",
      "p = 2.4275307676043548e-05\n"
     ]
    }
   ],
   "source": [
    "## Import the packages\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "## Define 2 random distributions\n",
    "#Sample Size\n",
    "N = 10\n",
    "#Gaussian distributed data with mean = 2 and var = 1\n",
    "a = np.random.randn(N) + 2\n",
    "#Gaussian distributed data with with mean = 0 and var = 1\n",
    "b = np.random.randn(N)\n",
    "\n",
    "## Calculate the Standard Deviation\n",
    "#Calculate the variance to get the standard deviation\n",
    "\n",
    "#For unbiased max likelihood estimate we have to divide the var by N-1, and therefore the parameter ddof = 1\n",
    "var_a = a.var(ddof=1)\n",
    "var_b = b.var(ddof=1)\n",
    "\n",
    "#std deviation\n",
    "s = np.sqrt((var_a + var_b)/2)\n",
    "s\n",
    "\n",
    "## Calculate the t-statistics\n",
    "t = (a.mean() - b.mean())/(s*np.sqrt(2/N))\n",
    "\n",
    "## Compare with the critical t-value\n",
    "#Degrees of freedom\n",
    "df = 2*N - 2\n",
    "\n",
    "#p-value after comparison with the t \n",
    "p = 1 - stats.t.cdf(t,df=df)\n",
    "\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(2*p))\n",
    "#Note that we multiply the p value by 2 because its a twp tail t-test\n",
    "### You can see that after comparing the t statistic with the critical t value (computed internally) we get a good p value of 0.0005 and thus we reject the null hypothesis and thus it proves that the mean of the two distributions are different and statistically significant.\n",
    "\n",
    "\n",
    "## Cross Checking with the internal scipy function\n",
    "t2, p2 = stats.ttest_ind(a,b)\n",
    "print(\"t = \" + str(t2))\n",
    "print(\"p = \" + str(2*p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    Q: What is bias-variance trade-off ? \n",
    "    Suppose we want to learn a function y = f(x) + eps.\n",
    "    We fit a function g to the observations (y_1, x_1), ..., (y_n, x_n).\n",
    "    Then g corresponds to our learned ML model.\n",
    "    \n",
    "    The generalization (mean square) error of an ML model can be typically decomposed into 3 parts as follows:\n",
    "    \n",
    "                       generalization error = bias^2 + variance + noise\n",
    "                       \n",
    "     where bias^2 is the error attributed to the inherent limitation of model to approximate f,\n",
    "           variance is the error part attributed to the variability in the predictions of the model,\n",
    "           and noise is the irreducible error attributed to the inherent noise in the dataset\n",
    "           \n",
    "     More precisely, for a fixed test example x:\n",
    "           generalization error = E[(y-g(x))^2]\n",
    "           bias(g) = E[g(x)-f(x)]\n",
    "           variance(g) = E[g(x)^2] - E[g(x)]^2\n",
    "           noise = variance(y) = variance(eps)\n",
    "           \n",
    "     Here the expectations are taken over a random choise of n-sample dataset D_n   \n",
    "     \n",
    "     Ideally, in order to achieve a low generalization error, \n",
    "     we want both bias and variance to be as close to zero as possible.\n",
    "     \n",
    "     However typically there is a trade-off between the two errors:\n",
    "           - models with very low bias tend to have high variance\n",
    "           - models with very low variance tend to have high bias\n",
    "           \n",
    "     This is partly because we are trying to infer an approximation of f by looking at its values\n",
    "     only on a limited set of points x_1, ..., x_n.\n",
    "     \n",
    "     If we choose g that approximates f too closely on these n points then g might capture some\n",
    "     patterns in this particular dataset that do not generalize on other points, leading to high variance.\n",
    "     \n",
    "     If we want to keep the variance low then we might not be able to approximate f too closely.\n",
    "     \n",
    "     Typically:\n",
    "         - high model complexity => high variance => overfitting\n",
    "         - low model complexity => high bias => underfitting\n",
    "         \n",
    "     Q: What are the situations in practice where one might want to use biased estimators ? \n",
    "         - when model is overfitting: \n",
    "           regularization achieves decrease in variance by small increase in bias\n",
    "           so that overall the generalization error decreases\n",
    "           https://stats.stackexchange.com/questions/207760/when-is-a-biased-estimator-preferable-to-unbiased-one\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/22898824/filtering-pandas-dataframes-on-dates\n",
    "\"\"\"\n",
    "    table: \n",
    "    date|timestamp|sender_id|receiver_id\n",
    "    \n",
    "    Goal: obtain fraction of messages that receive a response within 5 min on March 1, 2018\n",
    "    \n",
    "    df[df.date == datetime.date(2018, 03, 01)]\n",
    "    \n",
    "    \n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@franky07724_57962/using-keras-pre-trained-models-for-feature-extraction-in-image-clustering-a142c6cdf5b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 394s 4us/step\n"
     ]
    }
   ],
   "source": [
    "#Importing the ResNet50 model\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "#Loading the ResNet50 model with pre-trained ImageNet weights\n",
    "# include_top = False loads until the penultimate layer\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(200, 200, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating numpy representation of image ../Data/hymenoptera_data/train/ants/swiss-army-ant.jpg\n",
      "(200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "#scaler = transforms.Scale((224, 224))\n",
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                 std=[0.229, 0.224, 0.225])\n",
    "#to_tensor = transforms.ToTensor()\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "pic_one_path = '../Data/hymenoptera_data/train/ants/swiss-army-ant.jpg'\n",
    "\n",
    "image = Image.open(pic_one_path)\n",
    "\n",
    "print(\"Creating numpy representation of image {}\".format(pic_one_path))\n",
    "resize = image.resize((200,200), Image.NEAREST) \n",
    "resize.load()\n",
    "data = np.asarray(resize, dtype=\"uint8\" )\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Reshaping the training data\n",
    "#X_train_new = np.array([imresize(X_train[i], (200, 200, 3)) for i in range(0, len(X_train))]).astype('float32')\n",
    "\n",
    "X_train_new = np.array([data]).astype('float32')\n",
    "\n",
    "#Preprocessing the data, so that it can be fed to the pre-trained ResNet50 model. \n",
    "resnet_train_input = preprocess_input(X_train_new)\n",
    "\n",
    "#Creating bottleneck features for the training data\n",
    "train_features = model.predict(resnet_train_input)\n",
    "\n",
    "vector = train_features.reshape(1,2048)\n",
    "\n",
    "#Saving the bottleneck features\n",
    "np.savez('resnet_features_train', features=train_features)\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_features) = <class 'numpy.ndarray'> and train_features.shape = (1, 1, 1, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(\"type(train_features) = {} and train_features.shape = {}\".format(type(train_features), train_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the ResNet50 model\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "#Loading the ResNet50 model with pre-trained ImageNet weights\n",
    "# include_top = False loads until the penultimate layer\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(200, 200, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(image_path):\n",
    "    # 1. Load the image with Pillow library\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # 2. Resize image to the shape acceptable as input to the ResNet50 model\n",
    "    resized_image = image.resize((200, 200), Image.NEAREST)\n",
    "    resized_image.load()\n",
    "    \n",
    "    # 3. Preprocess the resized image so that in can be fed as an input to ResNet50\n",
    "    resized_image = np.asarray(resized_image, dtype=\"uint8\" )\n",
    "    X = np.array([resized_image]).astype('float32')\n",
    "    resnet_input = preprocess_input(X)\n",
    "    \n",
    "    # 4. Forward pass through model\n",
    "    last_layer_activations = model.predict(resnet_input)\n",
    "    \n",
    "    # 5. Reshape the activations to 1 dimensional vector\n",
    "    vector = last_layer_activations.reshape(1, 2048)\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between cat and dog = 0.35899585485458374\n",
      "similarity between cat and another_cat = 0.657699465751648\n",
      "similarity between dog and another_dog = 0.49333345890045166\n",
      "similarity between another_dog and another_cat = 0.3128197193145752\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "v_cat = get_vector('/home/raghav/Practice/MLPractice/Data/cats_and_dogs/cat.jpeg')\n",
    "v_dog = get_vector('../Data/cats_and_dogs/dog.jpeg')\n",
    "v_another_cat = get_vector('../Data/cats_and_dogs/another_cat.jpeg')\n",
    "v_another_dog = get_vector('../Data/cats_and_dogs/another_dog.jpeg')\n",
    "\n",
    "print(\"similarity between cat and dog = {}\".format(np.asscalar(cosine_similarity(v_cat, v_dog))))\n",
    "print(\"similarity between cat and another_cat = {}\".format(np.asscalar(cosine_similarity(v_cat, v_another_cat))))\n",
    "print(\"similarity between dog and another_dog = {}\".format(np.asscalar(cosine_similarity(v_dog, v_another_dog))))\n",
    "print(\"similarity between another_dog and another_cat = {}\".format(np.asscalar(cosine_similarity(v_another_dog, v_another_cat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(tf_gpu) Python3",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
